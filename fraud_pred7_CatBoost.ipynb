{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    使用XGB    max_depth=12      Score=\n",
    "                          15?\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test1 = pd.read_csv('./test1.csv')\n",
    "\n",
    "features = train.drop(['Unnamed: 0','label'],axis = 1)\n",
    "labels = train['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构造新特征，特征比大于15的特征为关键特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "osv1 created\n",
      "apptype1 created\n",
      "dev_height1 created\n",
      "dev_ppi1 created\n",
      "dev_width1 created\n",
      "media_id1 created\n",
      "ntt1 created\n",
      "fea1_hash1 created\n"
     ]
    }
   ],
   "source": [
    "#数据探索，找到导致1的关键特征值\n",
    "def find_key_feature(train,selected):\n",
    "    temp = pd.DataFrame(columns = [0,1])\n",
    "    temp[0] = train[train['label']==0][selected].value_counts()/len(train[train['label']==0]) \n",
    "    temp[1] = train[train['label']==1][selected].value_counts()/len(train[train['label']==1]) \n",
    "    temp[2] = temp[1]/temp[0]\n",
    "    #选出大于15倍的特征\n",
    "    result = temp[temp[2]>15].sort_values(2,ascending = False).index\n",
    "    return result\n",
    "\n",
    "key_features = {}\n",
    "selected_col = ['osv','apptype','carrier','dev_height','dev_ppi','dev_width',\n",
    "                'media_id','ntt','version','location','fea1_hash','cus_type']\n",
    "for selected in selected_col:\n",
    "    key_features[selected] = find_key_feature(train,selected)\n",
    "\n",
    "#构造新特征，新特征字段 = 原始特征字段+1\n",
    "def f1(x,selected):\n",
    "    #判断是否在关键特征值里，是1，否0\n",
    "    if x in key_features[selected]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "for selected in selected_col:\n",
    "    if len(key_features[selected]) > 0:\n",
    "        features[selected + '1'] = features[selected].apply(f1,args = (selected,))\n",
    "        test1[selected + '1'] = test1[selected].apply(f1,args = (selected,))\n",
    "        print(selected+'1 created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### osv转换为float类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对osv进行数据清洗\n",
    "import re\n",
    "def f2(x):\n",
    "    x = str(x)\n",
    "    x = x.replace('Android_','')\n",
    "    # 4.2.3.2是需要找到的字符\n",
    "    result = re.match('[\\d\\.]+',x)\n",
    "    if result:\n",
    "        x = result.group()    #返回匹配结果\n",
    "        if '.' in x:\n",
    "            #把4.4.3转化成4.43\n",
    "            #找到第一个小数点的位置\n",
    "            index1 = x.index('.')\n",
    "            if index1 > 0:\n",
    "                #去掉所有小数点\n",
    "                x = x.replace('.','')\n",
    "                #加上原来第一个小数点\n",
    "                x = float(x[0:index1]+'.'+x[index1:])\n",
    "        else: x = float(x)\n",
    "    else:\n",
    "        x = 0\n",
    "    #如果版本号过大，7930\n",
    "    if x>1000:\n",
    "        x = x/10000\n",
    "    elif x>11:\n",
    "        x = x/10\n",
    "    return x\n",
    "    \n",
    "features['osv'] = features['osv'].apply(f2)\n",
    "test1['osv'] = test1['osv'].apply(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特征筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#类别特征\n",
    "cate_features = ['apptype','carrier','ntt','version','location','cus_type']\n",
    "remove_list = ['os','lan','sid']\n",
    "col = features.columns.tolist()\n",
    "for i in remove_list:\n",
    "    col.remove(i)\n",
    "features = features[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  \n",
    "from datetime import datetime  \n",
    "\n",
    "def get_date(features):\n",
    "    #除以1000，转换为日期格式\n",
    "    features['timestamp'] = features['timestamp'].apply(lambda x:datetime.fromtimestamp(x/1000))\n",
    "    \n",
    "    #创建时间戳索引\n",
    "    temp = pd.DatetimeIndex(features['timestamp'])\n",
    "    features['year'] = temp.year\n",
    "    features['month'] = temp.month\n",
    "    features['day'] = temp.day\n",
    "    features['week_day'] = temp.weekday\n",
    "    features['hour'] = temp.hour\n",
    "    features['minute'] = temp.minute\n",
    "\n",
    "    #添加time_diff\n",
    "    start_time = features['timestamp'].min()\n",
    "    features['time_diff'] = features['timestamp'] - start_time\n",
    "    \n",
    "    #将time_diff转换为小时\n",
    "    features['time_diff'] = features['time_diff'].dt.days * 24 +features['time_diff'].dt.seconds/3600\n",
    "    \n",
    "    #使用day，time_diff\n",
    "    features.drop(['timestamp','year','month','minute','week_day'],axis = 1,inplace = True)\n",
    "  \n",
    "    return features\n",
    "\n",
    "#对训练集提取时间多尺度\n",
    "features = get_date(features)\n",
    "#对测试集提取时间多尺度\n",
    "test1 = get_date(test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对lan进行特征编码LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "#需要将训练集和测试集合并，然后统一做LabelEncoder\n",
    "all_df = pd.concat([train,test1])\n",
    "all_df['lan'] = all_df['lan'].astype('str')\n",
    "all_df['lan'] = le.fit_transform(all_df['lan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于数值过大的异常值，设置为0\n",
    "features['fea_hash'] = features['fea_hash'].map(lambda x: 0 if len(str(x))>16 else int(x))\n",
    "features['fea1_hash'] = features['fea1_hash'].map(lambda x: 0 if len(str(x))>16 else int(x))\n",
    "\n",
    "#对数据清洗，将V3=>3,V1=>1,V6=>6,V2=>2\n",
    "#针对version，非数值类型 设置0\n",
    "features['version'] = features['version'].map(lambda x: int(x) if str(x).isdigit() else 0)\n",
    "features['lan'] = all_df[all_df['label'].notnull()]['lan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试集做预测,保持与features中的columns一致\n",
    "test_fea = test1[features.columns]\n",
    "\n",
    "test_fea['fea_hash'] = test_fea['fea_hash'].map(lambda x: 0 if len(str(x))>16 else int(x))\n",
    "test_fea['fea1_hash'] = test_fea['fea1_hash'].map(lambda x: 0 if len(str(x))>16 else int(x))\n",
    "\n",
    "test_fea['version'] = test_fea['version'].map(lambda x: int(x) if str(x).isdigit() else 0)\n",
    "test_fea['lan'] = all_df[all_df['label'].isnull()]['lan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def ensemble_model(clf,train_x,train_y,test,categorical_features_indices):\n",
    "    #采用十折交叉验证\n",
    "    sk = StratifiedKFold(n_splits = 5,shuffle = True,random_state = 2021)\n",
    "    prob = [] #记录最终结果\n",
    "    mean_acc = 0 #记录平均准确率\n",
    "    for k,(train_index,val_index) in enumerate(sk.split(train_x,train_y)):\n",
    "        train_x_real = train_x.iloc[train_index]\n",
    "        train_y_real = train_y.iloc[train_index]\n",
    "        val_x = train_x.iloc[val_index]\n",
    "        val_y = train_y.iloc[val_index]\n",
    "        # 子模型训练\n",
    "        clf = clf.fit(train_x_real,train_y_real,cat_features = categorical_features_indices)\n",
    "        val_y_pred = clf.predict(val_x)\n",
    "        #子模型评估\n",
    "        acc_val = accuracy_score(val_y,val_y_pred)\n",
    "        print('第{}个子模型 acc{}'.format(k+1,acc_val))\n",
    "        mean_acc += acc_val/5\n",
    "        #子模型预测0,1\n",
    "        test_y_pred = clf.predict_proba(test)[:,-1] #soft得到概率值\n",
    "        prob.append(test_y_pred)\n",
    "    print(mean_acc)\n",
    "    mean_prob = sum(prob)/5\n",
    "    return mean_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  6,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "       23, 24, 26], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#categorical_features_indices\n",
    "#features.info()\n",
    "#float是数值类型，不是类别类型\n",
    "categorical_features_indices = np.where(features.dtypes != np.float)[0]\n",
    "categorical_features_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "c:/program files (x86)/go agent/pipelines/buildmaster/catboost.git/catboost/cuda/cuda_lib/cuda_base.h:281: CUDA error 35: CUDA driver version is insufficient for CUDA runtime version",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-94e126e35eaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mtask_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"GPU\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensemble_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_fea\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-2d56c0b94947>\u001b[0m in \u001b[0;36mensemble_model\u001b[1;34m(clf, train_x, train_y, test, categorical_features_indices)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mval_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# 子模型训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x_real\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y_real\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcat_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcategorical_features_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mval_y_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m#子模型评估\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   4300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_classification_objective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss_function'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4302\u001b[1;33m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0m\u001b[0;32m   4303\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4304\u001b[0m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1805\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1806\u001b[1;33m             self._train(\n\u001b[0m\u001b[0;32m   1807\u001b[0m                 \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1808\u001b[0m                 \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eval_sets\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1258\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1259\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCatBoostError\u001b[0m: c:/program files (x86)/go agent/pipelines/buildmaster/catboost.git/catboost/cuda/cuda_lib/cuda_base.h:281: CUDA error 35: CUDA driver version is insufficient for CUDA runtime version"
     ]
    }
   ],
   "source": [
    "import catboost as cb\n",
    "# 使用CatBoost训练\n",
    "clf = cb.CatBoostClassifier(\n",
    "             iterations=2000, depth=12, learning_rate=0.005, \n",
    "            loss_function='Logloss', early_stopping_rounds=50,\n",
    "            task_type = \"GPU\", verbose=0\n",
    ")\n",
    "result = ensemble_model(clf,features,labels,test_fea,categorical_features_indices)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存结果\n",
    "a = pd.DataFrame(test1['sid'])\n",
    "a['label'] =  result\n",
    "#转换为二分类\n",
    "a['label'] = a['label'].apply(lambda x:0 if x<0.5 else 1)\n",
    "a.to_csv('version7_CB2000.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
